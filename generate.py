from util import *
from constants import *
from SongRNN import *
import torch
import torch.optim as optim
import torch.nn as nn
import numpy as np

def generate_song(model, device, char_idx_map, max_len=1000, temp=0.8, prime_str='<start>', show_heatmap=False):
    """
    Generates a song using the provided model.

    Parameters:
    - model (nn.Module): The trained model used for generating the song
    - device (torch.device): The device (e.g., "cpu" or "cuda") on which the model is located
    - char_idx_map (dict): A map of characters to their index
    - max_len (int): The maximum length of the generated song
    - temp (float): Temperature parameter for temperature scaling during sampling
    - prime_str (str): Initialize the beginning of the song

    Returns:
    - generated_song (str): The generated song as a string
    """
    # to map index to char for each prediction
    idx_char_map = inv_map = {v: k for k, v in char_idx_map.items()}
    

    #Move model to the specified device and set the model to evaluation mode
    model.to(device)
    model.eval()

    # Initialize the hidden state
    model.init_hidden()
        
    with torch.no_grad(): # we don't need to calculate the gradient in the validation/testing
        # "build up" hidden state using the beginging of a song '<start>'
        generated_song = prime_str
        prime = characters_to_tensor(generated_song, char_idx_map)
        
        # Update hidden state using prime
        for i in range(len(prime)-1):
            inp = prime[i].unsqueeze(0).to(device)
            output, x1 = model(inp)
            if i == 0:
                heatmap = x1
            else:
                heatmap = np.append(heatmap, x1, axis=0)
                
        
        # Generate new chars
        while (generated_song[-len('<end>'):] != '<end>') and (len(generated_song) < max_len):
            '''
            TODOs: 
                - Continue generating the rest of the sequence until reaching the maximum length or encountering the end token.
                - Incorporate the temperature parameter to determine the generated/predicted character.
                - Add the generated character to the `generated_song` and then return `generated_song`.
            '''
            inp = characters_to_tensor(generated_song, char_idx_map)[-1].unsqueeze(0).to(device)
            output, x1 = model(inp)
            softmax_result = nn.Softmax(dim=0)(output[0] / temp)        
            pred_index = torch.multinomial(softmax_result, 1)[0].item()
            pred = idx_char_map[pred_index] 
            generated_song += pred
            heatmap = np.append(heatmap, x1, axis=0)
    
    # Turn the model back to training mode
    model.train()

    if show_heatmap:
        for i in np.arange(0, 150, 20):
            generate_heatmap(generated_song, heatmap, neuron_idx=i)
    
    generated_song = generated_song.replace("<start>", "").replace("<end>", "").strip()
    return generated_song

def generate_heatmap(generated_song, heatmap, neuron_idx=0):
    """
    Generates a heatmap using the provided generated song, heatmap chart values and neuron id.

    Parameters:
    - generated_song (nn.Module): The song generated by a trained model.
    - heatmap (np.array): heatmap/activation values from a particular layer of the trained model.
    - neuron_idx (int): id of the neuron to plot heatmap for.

    Returns:
        None
    """
    pad_factor = 50 # Number of columns in heatmap

    data = np.append(heatmap[:,neuron_idx], 0.0)

    padded_song, padded_data = pad(generated_song, data, pad_factor=pad_factor)
    
    padded_song = np.reshape(padded_song, (len(padded_song)//pad_factor, pad_factor))
    padded_data = np.reshape(padded_data, (len(padded_data)//pad_factor, pad_factor))
    plt.figure(figsize=(heatmap.shape[0]//20,heatmap.shape[1]//40))
    plt.title(f"Heatmap For Song RNN, Neuron ID: {neuron_idx}")
    
    heatplot = plt.pcolor(padded_data, edgecolors='k', linewidths=0.5, cmap='RdBu_r', vmin=-1.0, vmax=1.0)

    show_values(heatplot, song=padded_song)
    plt.colorbar(heatplot)
    plt.gca().invert_yaxis()
    plt.savefig(f"./plots/heatmap_{neuron_idx}.png")
    print(f"==> Heatmap saved for Neuron ID: {neuron_idx}..")
    return




# def generate_heatmap(generated_song, heatmap, neuron_idx=0):
#     """
#     Generates a heatmap using the provided generated song, heatmap chart values and neuron id.

#     Parameters:
#     - generated_song (nn.Module): The song generated by a trained model.
#     - heatmap (torch.Tensor): heatmap/activation values from a particular layer of the trained model.
#     - neuron_idx (int): id of the neuron to plot heatmap for.

#     Returns:
#         None
#     """
#     pad_factor = 20

#     data = np.append(heatmap[:,neuron_idx], 0.0)
#     padded_song, padded_data = pad(generated_song, data, pad_factor=pad_factor)

#     padded_song = np.reshape(padded_song, (len(padded_song)//pad_factor, pad_factor))
#     padded_data = np.reshape(padded_data, (len(padded_data)//pad_factor, pad_factor))

#     plt.figure(figsize=(heatmap.shape[0]//4,heatmap.shape[1]//4))
#     plt.title(f"Heatmap For Song RNN, Neuron ID: {neuron_idx}")
#     heatplot = plt.pcolor(padded_data, edgecolors='k', linewidths=4, cmap='RdBu_r', vmin=-1.0, vmax=1.0)

#     show_values(heatplot, song=padded_song)
#     plt.colorbar(heatplot)
#     plt.gca().invert_yaxis()
#     plt.savefig(f"./plots/heatmap_{neuron_idx}.png")
#     print(f"==> Heatmap saved for Neuron ID: {neuron_idx}..")
#     return
